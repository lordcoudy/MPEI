
<html>
<head>



<meta name="Description" content="Н. А. Олифер, В. Г. Олифер, Центр Информационных Технологий. Управление памятью в Mach
">


<title>Управление памятью в Mach
</title>
</HEAD><BODY bgcolor="#FFF5EE" text="#000000" link="#FF0000" alink="#FF0000" vlink="#A52A2A">

<h3><a name="_6_3">Управление памятью в Mach</a></h3>
<p>
Ядро Mach имеет мощную, тщательно разработанную и в высшей степени гибкую систему управления памятью, основанную на страничном механизме и обладающую многими редкими свойствами. В частности, в нем машинно-зависимая часть кода отделена от машинно-независимой части чрезвычайно ясным и необычным способом. Это разделение делает управление памятью более мобильным, чем в других системах. Кроме того, система управления памятью тесно взаимодействует с коммуникационной системой.
<p>
Одной из основных особенностей системы управления памятью Mach является то, что ее код разбит на три части. Первая часть называется <i>pmap, </i>который работает в ядре и занимается работой с устройством отображения виртуальных адресов в физические (Memory Management Unit, MMU). Эта часть устанавливает значения регистров MMU и аппаратных страничных таблиц, а также перехватывает все страничные прерывания. Эта часть кода зависит от архитектуры MMU и должна быть переписана для каждой новой машины всякий раз, когда Mach на нее переносится. Вторая часть - это машинно-независимый код ядра, и он связан с обработкой страничных сбоев, управляет отображением областей памяти и заменой страниц.
<p>
Третья часть кода работает в пользовательском пространстве в качестве процесса, называемого &quot;менеджер памяти&quot; (memory manager) или иногда &quot;внешний менеджер страниц&quot; (external pager). Эта часть имеет дело с логическими аспектами (в отличие от физических) системы управления памятью, в основном, с управлением хранения образов памяти на диске. Например, менеджер памяти отслеживает информацию о том, какие виртуальные страницы используются, какие находятся в оперативной памяти и где они хранятся на диске, когда не находятся в оперативной памяти. Ядро и менеджер памяти взаимодействуют с помощью хорошо определенного протокола, что дает возможность для пользователей ядра Mach писать свои собственные менеджеры памяти. Такое разделение обязанностей позволяет реализовывать страничные системы специльного назначения. При этом ядро становится потенциально меньше и проще, так как значительная часть кода работает в пользовательском пространстве. С другой стороны, это и источник усложнения ядра, так как при этом оно должно защищать себя от ошибок или некорректной работы менеджера памяти. Кроме того, при наличии двух активных частей системы управления памятью возможно возникновение гонок между ними.
<h4><a name="_6_3_1">Виртуальная память</a></h4>
<p>
Концептуально модель памяти в Mach выглядит для пользовательских процессов в виде большого линейного виртуального адресного пространства. Для большинства 32-х разрядных процессоров адресное пространство занимает диапазон от 0 до 2<sup>32</sup> - 1 (4 Гбайта). Адресное пространство поддерживается страничным механизмом.
<p>
Mach обеспечивает очень тонкое управление механизмом использования виртуальных страниц (для тех процессов, которые интересуются этим). Для начала скажем о том, что адресное пространство может использоваться разреженным способом. Например, процесс может иметь дюжину секций виртуального адресного пространства, каждая из которых находится на расстоянии сотен мегабайт от ближайшего соседа, с большими зазорами неиспользуемого адресного пространства между этими секциями.
<p>
Теоретически любое виртуальное адресное пространство может быть разреженным, так что способность использовать большое количество разбросанных секций не является в действительности свойством архитектуры виртуальной памяти. Другими словами, любая 32-х битная машина должна позволять процессу иметь 50 000 секций данных, разделенных промежутками по 100 Мбайт, в пределах от 0 до 4 Гбайт. Однако, во многих реализациях линейная страничная таблица от 0 до самой старшей используемой страницы хранится в памяти ядра. На машине с размером страницы в 1 Kб эта конфигурация требует 4 миллиона элементов таблицы страниц, делая такую схему очень дорогой, если не невозможной. Даже при многоуровневой организации страничной таблицы такая разреженность в лучшем случае неприемлема. В ядре Mach при его разработке изначально ставилась задача полной поддержки разреженных адресных пространств.
<p>
Для того, чтобы определить, какие виртуальные адреса используются, а какие нет, Mach обеспечивает способ назначения и отмены секций виртуального адресного пространства, называемых <i>областями</i> (regions). В вызове для назначения области можно определить базовый адрес и размер, и область выделяется там, где это указано. В другом случае может быть задан только размер области, а система сама находит подходящий диапазон адресов и возвращает базовый адрес. Виртуальный адрес является действительным только в том случае, когда он попадает в назначенный диапазон. Попытка использовать адрес из промежутков между назначенными областями вызывает прерывание, которое может быть перехвачено самим процессом, если он этого пожелает.
<p>
<center><img src = "img00092.gif" tppabs="http://ndesign.com.ua/~mik/doc/sos/pictures/img00092.gif" border=1></center>

<p align=center>
<i>Рис. 6.5. Адресное пространство с назначенными областями,
<br></i>
<i>отображенными объектами и неиспользуемыми адресами</i>
<p>
Ключевым понятием, связанным с использованием виртуального адресного пространства, является <i>объект памяти</i> (memory object). Объект памяти может быть страницей или набором страниц, а также может быть файлом или другой, более специальной, структурой данных, например, записью базы данных. Объект памяти может быть отображен в неиспользуемую часть виртуального адресного пространства, формируя новую область, как это показано на рисунке 6.5. Когда файл отображен в виртуальное адресное пространство, то его можно читать или в него можно писать с помощью обычных машинных команд. Отображенные (mapped) файлы постранично вытесняются из памяти обычным образом. Когда процесс завершается, то его отображенные в память файлы автоматически возвращаются в файловую систему вместе со всеми изменениями, произошедшими с их содержанием в то время, когда они были отображены в память. Также возможно отменить отображение файла или другого объекта памяти, освобождая его адресное пространство и делая его доступным для последовательного его распределения или отображения.
<p>
Конечно, отображение файлов в память не единственный способ доступа к ним. Их содержимое можно читать и обычным способом. Однако и в этом случае библиотечные функции могут отображать файлы в память помимо желания пользователя, а не использовать систему ввода-вывода. Такой способ позволяет страницам файлов использовать систему виртуальной памяти, а не специально выделенные буфера где-либо в системе.
<p>
Mach поддерживает некоторое количество вызовов для работы с виртуальным адресным пространством. Основные приведены в таблице 6.3. Они не являются истинными системными вызовами. Вместо этого все они используют запись сообщения в порт процесса для вызова соответствующих функций ядра.
<p align=right>
<i><b>Таблица 6.3.
<br></b></i>
<i>Примитивы для управления виртуальным адресным пространством</i>

<table border=1 width=100%><tr><td align=center colspan= 31><b>Вызов</b><td align=center colspan= 126><b>Описание</b>
<tr><td  colspan= 31>Allocate<td  colspan= 126>Делает область виртуального адресного пространства используемой
<tr><td  colspan= 31>Deallocate<td  colspan= 126>Освобождает область виртуального адресного пространства
<tr><td  colspan= 31>Map<td  colspan= 126>Отображает объект памяти в виртуальное пространство
<tr><td  colspan= 31>Copy<td  colspan= 126>Копирует область в другой диапазон виртуальных адресов
<tr><td  colspan= 31>Inherit<td  colspan= 126>Устанавливает атрибут наследования для области
<tr><td  colspan= 31>Read<td  colspan= 126>Читает данные из адресного пространства другого процесса
<tr><td  colspan= 31>Write<td  colspan= 126>Записывает данные в адресное пространство другого процесса
</table>
<p>
Первый вызов, <i>Allocate, </i>делает область виртуальных адресов используемой. Процесс может наследовать назначенное адресное пространство, а может и назначить дополнительное, но любая попытка обратиться к неназначенному адресу будет вызывать ошибку. Второй вызов, D<i>eallocate, </i>освобождает область (то есть удаляет ее из карты памяти), что дает возможность назначить ее заново или отобразить что-нибудь в нее, используя вызов M<i>ap</i>.
<p>
Вызов C<i>opy</i> копирует объект памяти в новую область. Оригинальная область остается неизменной. Операция C<i>opy </i>выполняется оптимизированным способом с использованием разделяемых страниц, чтобы избежать физического копирования.
<p>
Вызов <i>Inherit </i>влияет на способ наследования областью свойств при создании нового процесса. Адресное пространство может быть сконфигурировано так, что некоторые области будут наследовать свойства, а некоторые нет. Это будет обсуждаться ниже.
<p>
Вызовы <i>Read</i> и <i>Write </i>позволяют нити получить доступ к виртуальной памяти, относящейся к другому процессу. Эти вызовы требуют, чтобы вызывающая нить имела права доступа к порту другого процесса, которые процесс может предоставить, если захочет этого.
<p>
В дополнение к вызовам, перечисленным в таблице 6.3, существует несколько других. Эти вызовы связаны, в основном, с установкой и чтением атрибутов, режимами защиты и различными видами статистической информации.
<h4><a name="_6_3_2">Разделение памяти</a></h4>
<p>
Разделение играет важную роль в Mach. Для разделения объектов нитями одного процесса никаких специальных механизмов не требуется: все они автоматически видят одно и то же адресное пространство. Если одна из них имеет доступ к части данных, то и все его имеют. Более интересной является возможность разделять двумя или более процессами одни и те же объекты памяти, или же просто разделять страницы памяти для этой цели. Иногда разделение полезно в системах с одним процессором. Например, в классической задаче производитель-потребитель может быть желательным реализовать производителя и потребителя разными процессами, но иметь общий буфер, в который производитель мог бы писать, а потребитель - брать из него данные.
<p>
В многопроцессорных системах разделение объектов между процессами часто более важно, чем в однопроцессорных. Во многих случаях задача решается за счет работы взаимодействующих процессов, работающих параллельно на разных процессорах (в отличие от разделения во времени одного процессора). Этим процессам может понадобиться непрерывный доступ к буферам, таблицам или другим структурам данных, для того, чтобы выполнить свою работу. Существенно, чтобы ОС позволяла такой вид разделения. Ранние версии UNIX'а не предоставляли такой возможности, хотя потом она была добавлена.
<p>
Рассмотрим, например, систему, которая анализирует оцифрованные спутниковые изображения Земли в реальном масштабе времени, в том темпе, в каком они передаются со спутника. Такой анализ требует больших затрат времени, и одно и то же изображение может проверяться на возможность его использования в предсказании погоды, урожая или отслеживании загрязнения среды. Каждое полученное изображение сохраняется как файл.
<p>
Для проведения такого анализа можно использовать мультипроцессор. Так как метеорологические, сельскохозяйственные и экологические программы очень отличаются друг от друга и разрабатываются различными специалистами, то нет причин делать их нитями одного процесса. Вместо этого каждая программа является отдельным процессом, который отображает текущий снимок в свое адресное пространство, как показано на рисунке 6.6. Заметим, что файл, содержащий снимок, может быть отображен в различные виртуальные адреса в каждом процессе. Хотя каждая страница только один раз присутствует в памяти, она может оказаться в картах страниц различных процессов в различных местах. С помощью такого способа все три процесса могут работать над одним и тем же файлом в одно и то же время.
<p>
Другой важной областью разделяемости является создание процессов. Как и в UNIX'е, в Mach основным способом создания нового процесса является копирование существующего процесса. В UNIX'е копия всегда является двойником процесса, выполнившего системный вызов FORK в то время как в Mach потомок может быть двойником другого процесса (прототипа).
<p>
Одним из способов создания процесса-потомка состоит в копировании всех необходимых страниц и отображения копий в адресное пространство потомка. Хотя этот способ и работает, но он необоснованно дорог. Коды программы обычно используются в режиме только-для-чтения, так что их нельзя изменять, часть данных также может использоваться в этом режиме. Страницы с режимом только-для-чтения нет необходимости копировать, так как отображение их в адресные пространства обоих процессов выполнит необходимую работу. Страницы, в которые можно писать, не всегда могут разделяться, так как семантика создания процесса (по крайней мере в UNIX) говорит, что хотя в момент создания родительский процесс и процесс-потомок идентичны, последовательные изменения в любом из них невидимы в другом адресном пространстве.
<p>
Кроме этого, некоторые области (например, определенные отображенные файлы) могут не понадобиться процессу-потомку. Зачем связываться с массой забот, связанных с отображением, если эти области просто не нужны?
<p>
<center><img src = "img00093.gif" tppabs="http://ndesign.com.ua/~mik/doc/sos/pictures/img00093.gif" border=1></center>

<p align=center>
<i>Рис. 6.6. Три процесса, разделяющие отображенный файл</i>
<p>
Для обеспечения гибкости Mach позволяет процессу назначить <i>атрибут наследования</i><b> </b>каждой области в адресном пространстве. Различные области могут иметь различные значения атрибута. Предусмотрены три значения атрибута:
<OL TYPE = 1>
<LI>Область не используется в процессе-потомке.
<LI>Область разделяется между процессом-прототипом и потомком.
<LI>Область в процессе-потомке является копией прототипа.
</OL>
<p>
Если область имеет первое значение, то в процессе-потомке она отсутствует. Ссылки на нее рассматриваются как и любые другие ссылки на неназначенную процессу память - они вызывают прерывания. Потомок может назначить эту область для своих собственных целей, или отобразить в нее объект памяти.
<p>
Второй вариант представляет собой истинное разделение памяти. Страницы области присутствуют как в адресном пространстве прототипа, так и потомка. Изменения, сделанные в одном пространстве, видны в другом. Этот вариант не используется при реализации системного вызова FORK, но часто бывает полезен для других целей.
<p>
Третья возможность - копирование всех страниц области и отображение копий в адресное пространство потомка. FORK использует этот вариант. В действительности Mach не выполняет реального копирования страниц, а использует вместо этого стратегию, называемую<i> копирование-при-записи</i> (copy-on-write). Она состоит в том, что все необходимые страницы помещаются в карту виртуальной памяти потомка, но помечаются при этом как предназначенные только для чтения, как это показано на рисунке 6.7. Пока потомок только читает из этих страниц, все работает замечательно.
<p>
Однако, если потомок пытается писать в одну из этих страниц, происходит прерывание по защите памяти. Затем операционная система делает копию этой страницы и отображает копию в адресное пространство потомка, заменяя ей защищенную от записи страницу. Новая страница помечается как доступная для чтения и записи. На рисунке 6.7, б потомок пытается произвести запись в страницу 7. Это действие приводит к тому, что страница 7 копируется в страницу 8, а страница 8 отражается в адресное пространство вместо страницы 7. Страница 8 помечается для чтения и записи, так что запись в нее не вызовет прерывание.
<p>
<center><img src = "img00094.gif" tppabs="http://ndesign.com.ua/~mik/doc/sos/pictures/img00094.gif" border=1></center>

<p align=center>
<i>Рис. 6.7. Операция "копирование-при-записи"
<br></i>
<i>а - после вызова FORK все страницы потомка помечаются "только-для-чтения"
<br></i>
<i>б - при записи потомка в страницу 7 делается ее копия</i>
<p>
Механизм <i>копирование-при-записи</i> имеет несколько преимуществ по сравнению со способом прямого копирования всех страниц в момент создания нового процесса. Во-первых, некоторые страницы имеют режим только-для-чтения, поэтому в их копировании нет необходимости. Во-вторых, к другим страницам обращений может никогда и не быть, поэтому, хотя потенциально в них может производиться запись, копировать их также не нужно. В третьих, хотя некоторые страницы и доступны для записи, но процесс-потомок может удалить их из своего адресного пространства, не использовав. Поэтому при использовании описанного механизма копируются только те страницы, копирование которых необходимо.
<p>
Механизм <i>копирование-при-записи</i> обладает и недостатками. С одной стороны, он требует более сложного администрирования, так как система должна хранить информацию о том, какие страницы действительно защищены от записи (так что обращение к ним является ошибкой), а какие нужно копировать при записи. С другой стороны, <i>копирование-при-записи</i> приводит к большому количеству прерываний ядра, по одному на каждую страницу, в которую происходит запись. В зависимости от аппаратуры, одно прерывание ядра, сопровождаемое копированием большого количества страниц, может оказаться эффективнее, чем многочисленные прерывания ядра, свойственные механизму <i>копирование-при-записи</i>. Наконец, механизм <i>копирование-при-записи</i> плохо работает через сеть, потому что в этом случае всегда (то есть при доступе к разделяемым страницам) нужен физический транспорт, так что преимущество этого механизма, связанное с невыполнением копирования только читаемых данных, теряется.
<h4><a name="_6_3_3">Внешние менеджеры памяти</a></h4>
<p>
В начале нашего обсуждения средств управления памятью в Mach мы кратко упомянули о менеджерах памяти пользовательского режима. Теперь рассмотрим их более детально. Каждый объект памяти, который отображается в адресное пространство процесса, должен иметь внешний менеджер памяти, который им управляет. Объекты памяти различных классов управляются различными менеджерами памяти. Каждый из них может реализовывать свою собственную семантику, может решать, где хранить данные страниц, которые не находятся в физической памяти, и следовать своим собственным правилам при решении вопроса о том, что делать с объектами после того, как их отображение в память отменяется.
<p>
Для того, чтобы отобразить какой-либо объект в адресное пространство процесса, этот процесс посылает сообщение менеджеру памяти, запрашивая операцию отображения. Для того, чтобы выполнить эту работу, нужны три порта. Первый, <i>порт объекта</i><b> </b>(object port), создается менеджером памяти и используется в дальнейшем ядром для информирования менеджера памяти о страничных отказах и других событиях, связанных с объектом. Второй порт, <i>порт управления</i>, создается самим ядром, так что менеджер памяти может реагировать на эти события (многие из них требуют проведения некоторых действий менеджером памяти). Использование различных портов связано с тем, что порты являются однонаправленными. В порт объекта пишет ядро, а читает менеджер памяти, а порт управления работает в обратном направлении.
<p>
Третьим является <i>порт имени</i> (name port), который используется как разновидность имени, с помощью которого идентифицируется объект. Например, нить может передать ядру виртуальный адрес и спросить, к какой области он относится. Ответом будет указатель на порт имени. Если адреса относятся к одной и той же области, то они будут идентифицироваться одним и тем же портом имени.
<p>
Когда менеджер памяти отображает объект, он обеспечивает создание порта объекта как одного из параметров. Затем ядро создает два других порта и посылает инициализирующее сообщение на порт объекта, несущее информацию о портах управления и имени. Затем менеджер памяти посылает ответ, сообщая ядру о том, какими являются атрибуты объекта, а также о том, нужно или нет хранить объект в кэше после того, как отображение будет отменено. Изначально все страницы объекта помечаются как запрещенные по чтению и записи, чтобы вызвать прерывание при первом использовании.
<p>
В этом месте менеджер памяти выполняет чтение порта объекта и блокирует себя. Нить, которая отобразила объект, с этого момента разблокируется и может выполняться. Менеджер памяти простаивает до тех пор, пока ядро не попросит его что-либо сделать, записав сообщение в порт объекта.
<p>
Раньше или позже, нить несомненно попытается прочитать страницу или записать в страницу, относящуюся к объекту памяти. Ядро при этом пошлет сообщение менеджеру памяти через порт объекта, информируя его о том, к какой странице произошло обращение, и попросит менеджер обеспечить эту страницу. Это сообщение является асинхронным, так как ядро не решается заблокировать любую из своих нитей в ожидании ответа от пользовательского процесса, которого может и не быть. Во время ожидания ответа ядро приостанавливает вызвавшую обращение к странице нить и ищет другие нити для выполнения.
<p>
Когда менеджер памяти узнает о страничном отказе, он проверяет, является ли обращение разрешенным. Если нет, то он посылает ядру сообщение об ошибке. Если же отображение разрешено, менеджер памяти получает страницу тем методом, который подходит для этого объекта. Если объект является файлом, то менеджер памяти ищет корректный адрес и читает страницу в собственное адресное пространство. Затем он посылает ответ ядру, снабжая его указателем на эту страницу.
<p>
Ядро отображает страницу в адресное пространство вызвавшего обращение процесса. Теперь нить может быть разблокирована. Этот процесс повторяется до тех пор, пока все нужные страницы не загрузятся.
<p>
Чтобы быть уверенным в том, что существует необходимый запас свободных страничных кадров, нить страничного демона время от времени просыпается и проверяет состояние памяти. Если свободных страничных кадров физической памяти недостаточно, то она собирает информацию о старых &quot;грязных&quot; страницах и отсылает ее менеджеру памяти, ответственному за объект, которому принадлежат страницы. Ожидается, что менеджер памяти запишет эти страницы на диск и сообщит, когда эта операция будет завершена. Если страница относится к файлу, то менеджер сначала найдет смещение страницы в файле, а затем запишет ее туда. Используемый при этом алгоритм замены - это второй вопрос.
<p>
Стоит заметить, что страничный демон является частью ядра. Хотя алгоритм замены страниц полностью машинно-независим, в ситуации, когда память заполнена страницами, которые управляются разными менеджерами, нет приемлемого способа разрешить одному из них принимать решение о том, какую страницу нужно вытеснить из памяти. Единственным приемлемым способом является статическое распределение страничных кадров между различными менеджерами и разрешение каждому из них заменять страницы в пределах этого набора. Однако из-за того, что глобальный алгоритм, вообще говоря, более эффективен, чем локальный, такой подход не используется.
<p>
В дополнение к особым менеджерам памяти, которые отображают файлы и другие специальные объекты, имеется менеджер памяти &quot;по умолчанию&quot; (default) для &quot;обычного&quot; отображения страниц. Когда процесс просит выделить ему область виртуального адресного пространства с помощью вызова <i>Allocate,</i> то фактически происходит отображение объекта, управляемого менеджером памяти &quot;по умолчанию&quot;. Этот менеджер поставляет заполненные нулями страницы, если это необходимо. Он использует временный файл для образования пространства на диске для свопинга страниц, а не специальную область на диске, как это делается в UNIX'е.
<p>
Чтобы концепция внешнего менеджера памяти заработала, должен существовать и использоваться строго определенный протокол взаимодействия между ядром и менеджером памяти. Этот протокол состоит из небольшого количества типов сообщений, которыми обмениваются ядро и менеджер. Любое взаимодействие между ними инициируется ядром в форме асинхронных сообщений, посылаемых в порт объекта некоторого объекта памяти. В ответ на него менеджер посылает асинхронный ответ на порт управления.
<p>
В таблице 6.4 приведен список типов сообщений, которые ядро посылает менеджеру памяти.
<p align=right>
<i><b>Таблица 6.4.
<br></b></i>
<i>Некоторые типы сообщений, посылаемых ядром менеджеру сообщений</i>

<table border=1 width=100%><tr><td align=center colspan= 30><b>Вызов</b><td align=center colspan= 128><b>Описание</b>
<tr><td  colspan= 30>Init<td  colspan= 128>Инициализировать новый отображенный в память объект 
<tr><td  colspan= 30>Data_request<td align=left colspan= 128>Передать ядру определенную страницу для обработки страничного отказа 
<tr><td  colspan= 30>Data_write<td  colspan= 128>Взять страницу из памяти и переписать ее
<tr><td  colspan= 30>Data_unlock<td  colspan= 128>Разблокирует страницу, так что ядро может ее использовать 
<tr><td  colspan= 30>Lock_completed<td  colspan= 128>Завершено выполнение предшествующий запрос Lock_request
<tr><td  colspan= 30>Terminate<td  colspan= 128>Информирование о том, что данный объект больше не используется
</table>
<p>
Когда объект отображается в память с использованием вызова <i>Map, </i>то ядро посылает сообщение <i>Init </i>соответствующему менеджеру памяти, чтобы позволить ему инициализировать себя. Это сообщение определяет порты, которые должны будут использоваться позже в диалоге с объектом. Запросы от ядра на получение страницы и поставку страницы осуществляются с помощью вызовов <i>Data_request</i> и <i>Data_write</i> соответственно. Эти сообщения управляют трафиком страниц в обоих направлениях, и поэтому являются наиболее важными вызовами.
<p>
Сообщение <i>Data_unlock</i> представляет собой запрос от ядра менеджеру памяти на разблокирование заблокированной страницы, так что ядро может использовать ее для другого процесса. Сообщение <i>Lock_completed</i> оповещает о завершении последовательности <i>Lock_request</i>, и будет рассмотрен ниже. Наконец, сообщение <i>Terminate</i> сообщает менеджеру памяти, что объект, имя которого указано в вызове, больше не используется и может быть удален из памяти. Существуют вызовы, определенные для менеджера памяти &quot;по умолчанию&quot;.
<p>
Сообщения, перечисленные в таблице 6.5, передаются от внешнего менеджера памяти ядру.
<p align=right>
<i><b>Таблица 6.5.
<br></b></i>
<i>Сообщения, посылаемые менеджером памяти ядру</i>

<table border=1 width=100%><tr><td align=center colspan= 32><b>Вызов</b><td align=center colspan= 125><b>Описание</b>
<tr><td  colspan= 32>Set_attributes<td  colspan= 125>Ответ на вызов Init
<tr><td  colspan= 32>Data_provided<td  colspan= 125>Ответ на вызов Data_request - здесь: запрошенная страница доставлена 
<tr><td  colspan= 32>Data_unavailable<td  colspan= 125>Ответ на вызов - страницы нет в наличии
<tr><td  colspan= 32>Lock_request<td  colspan= 125>Запрашивает ядро для выполнения очистки, вытеснения или блокировки страниц
<tr><td  colspan= 32>Destroy<td  colspan= 125>Разрушить объект, который больше не нужен
</table>
<p>
Первое сообщение, <i>Set_attributes, </i>является ответом на сообщение <i>Init. </i>Оно сообщает ядру, что менеджер готов обрабатывать вновь отображенный объект. Ответ также содержит биты режима для объекта и говорит ядру, следует или нет кэшировать объект, даже если ни один процесс в какой-либо момент времени не отображает его. Следующие два сообщения являются ответами на сообщение <i>Data_request</i>. Это сообщение запрашивает страницу у менеджера памяти. Ответ менеджера зависит от того, может он предоставить страницу или нет. Первое сообщение говорит о том, что может, второе - о том, что нет.
<p>
Сообщение <i>Lock_request</i> позволяет менеджеру памяти попросить ядро очистить некоторые страницы, то есть послать ему эти страницы, чтобы они могли быть записаны на диск. Это сообщение может быть использовано также и для того, чтобы изменить режим защиты страниц (чтение, запись, выполнение). Наконец, сообщение <i>Destroy</i> служит для уведомления ядра о том, что некоторый объект больше не нужен.
<p>
Необходимо обратить внимание на то, что когда ядро посылает сообщение менеджеру памяти, оно в действительности выполняет вызов. Хотя при этом способе гибкость повышается, некоторые разработчики систем считают, что это неэлегантно - ядру вызывать пользовательский процесс для выполнения для ядра некоторого сервиса. Эти люди обычно верят в иерархические системы, когда нижние уровни обеспечивают сервис для верхних, а не наоборот.
<h4><a name="_6_3_4">Распределенная разделяемая память в Mach</a></h4>
<p>
Концепция внешних менеджеров памяти в Mach хорошо подходит для реализации распределенной страничной разделяемой памяти. В этом разделе будут кратко описаны некоторые из работ, выполненные в этой области. Основная идея состоит в том, чтобы получить единое, линейное виртуальное адресное пространство, которое разделяется между процессами, работающими на компьютерах, которые не имеют какой-либо физической разделяемой памяти. Когда нить ссылается на страницу, которой у нее нет, то происходит страничное прерывание. Требуемая страница отыскивается на одном из дисков сети, доставляется на ту машину, где произошел страничный сбой, и помещается в физическую память, так что нить может продолжать работать.
<p>
Так как Mach уже имеет менеджеры памяти для различных классов объектов, то естественно ввести новый объект памяти - <i>разделяемую страницу</i>. Разделяемые страницы управляются одним или более специальными менеджерами памяти. Одной из возможностей является существование единого менеджера памяти, который управляет всеми разделяемыми страницами. Другой вариант состоит в том, что для каждой разделяемой страницы или набора разделяемых страниц используется свой менеджер памяти, чтобы распределить нагрузку.
<p>
Еще одна возможность состоит в использовании различных менеджеров памяти для страниц с различной семантикой. Например, один менеджер памяти мог бы гарантировать полную согласованность памяти, означающую, что любое чтение, следующее за записью, всегда будет видеть самые свежие данные. Другой менеджер памяти мог бы предоставлять более слабую семантику, например, что чтение никогда не возвращает данные, которые устарели более, чем на 30 секунд.
<p>
Рассмотрим наиболее общий случай: одна разделяемая страница, централизованное управление и полная согласованность памяти. Все остальные страницы локальны для каждой отдельной машины. Для реализации этой модели нам понадобится один менеджер памяти, который обслуживает все машины системы. Назовем его сервером распределенной разделяемой памяти (Distributed Shared Memory, DSM). DSM-сервер обрабатывает ссылки на разделяемую страницу. Обычные менеджеры памяти управляют остальными страницами. До сих пор мы молчаливо подразумевали, что менеджер или менеджеры памяти, которые обслуживают данную машину, должны быть локальными для этой машины. Фактически, из-за того, что коммуникации прозрачны в Mach, менеджер памяти не обязательно располагается на той машине, чьей памятью он управляет.
<p>
Разделяемая страница всегда доступна для чтения или записи. Если она доступна для чтения, то она может копироваться (реплицироваться) на различные машины. Если же она доступна для записи, то должна быть только одна ее копия. DSM-сервер всегда знает состояние разделяемой страницы, а также на какой машине или машинах она в настоящий момент находится. Если страница доступна для чтения, то DSM-сервер сам имеет ее действительную копию.
<p>
Предположим, что страница является доступной для чтения, и нить, работающая на какой-то машине, пытается ее прочитать. DSM-сервер просто посылает этой машине копию страницы, обновляет свои таблицы, чтобы зафиксировать еще одного читателя, и завершает на этом данную работу. Страница будет отображена в новой машине и помечена "для чтения".
<p>
Теперь предположим, что один из читателей пытается осуществить запись в эту страницу. DSM-сервер посылает сообщение ядру или ядрам, которые имеют эту страницу, с просьбой вернуть ее. Сама страница не должна передаваться, так как DSM-сервер имеет ее действительную копию. Все, что требуется, это подтверждение, что страница больше не используется. После того, как все ядра освободят страницу, писатель получает ее копию вместе с разрешением использовать ее для записи.
<p>
Если теперь кто-либо еще хочет использовать эту страницу (которая теперь доступна для записи), DSM-сервер говорит текущему ее владельцу, что ее нужно прекратить использовать и вернуть. Когда страница возвращается, она может быть передана одному или нескольким читателям или одному писателю. Возможны многие вариации этого централизованного алгоритма, например, не запрашивать возвращение страницы до тех пор, пока машина, владеющая ею, не попользуется в течение некоторого минимального времени. Возможно также и распределенное решение.

<p><center><a href="glava_25.htm" tppabs="http://ndesign.com.ua/~mik/doc/sos/glava_25.htm">Предыдущая глава</a> || <a href="contents.htm" tppabs="http://ndesign.com.ua/~mik/doc/sos/contents.htm">Оглавление</a> || <a href="glava_27.htm" tppabs="http://ndesign.com.ua/~mik/doc/sos/glava_27.htm">Следующая глава</a><p>
<p><p>
<center><font size=1>
Copyright &copy <a href="cit.htm#1" tppabs="http://ndesign.com.ua/~mik/doc/sos/cit.htm#1">CIT</a>
</font></center>
</body></html>
